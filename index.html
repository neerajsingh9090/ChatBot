<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>WebRTC Manual Offer/Answer</title>
</head>
<body>
  <h2>ðŸŽ¤ WebRTC Manual Offer/Answer Exchange</h2>

  <button onclick="start()">Start Microphone</button>
  <button onclick="createOffer()">Create Offer</button>
  <button onclick="setRemoteAndCreateAnswer()">Set Remote Offer + Create Answer</button>
  <button onclick="setRemoteAnswer()">Set Remote Answer</button>

  <h3>Local SDP (Offer or Answer)</h3>
  <textarea id="localSdp" cols="80" rows="10"></textarea>

  <h3>Remote SDP</h3>
  <textarea id="remoteSdp" cols="80" rows="10"></textarea>

  <p id="status" style="color: green;"></p>
  <h3>Transcribed Text</h3>
  <textarea id="transcript" cols="80" rows="10" readonly></textarea>

  <script>
    let pc;
    let localStream;
    let dataChannel;
    let transcriptHistory = [];

    async function start() {
      localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      document.getElementById('status').textContent = "Microphone access granted";
    }

    async function createPeerConnection(isOfferer = false) {
      pc = new RTCPeerConnection();

      pc.onicecandidate = e => {
        if (e.candidate === null) {
          document.getElementById('localSdp').value = JSON.stringify(pc.localDescription);
        }
      };

      pc.ontrack = (e) => {
        const audio = new Audio();
        audio.srcObject = e.streams[0];
        audio.autoplay = true;
        document.getElementById('status').textContent = "Receiving audio from remote peer";
        startSpeechRecognition();
      };

      if (isOfferer) {
        dataChannel = pc.createDataChannel('transcript');
        setupDataChannel();
      } else {
        pc.ondatachannel = (event) => {
          dataChannel = event.channel;
          setupDataChannel();
        };
      }

      if (localStream) {
        localStream.getTracks().forEach(track => pc.addTrack(track, localStream));
      }
    }

    function setupDataChannel() {
      dataChannel.onmessage = (event) => {
        addTranscript('Remote', event.data);
      };
    }

    async function createOffer() {
      await createPeerConnection(true);
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);
      document.getElementById('status').textContent = "Offer created";
      
    }

    async function setRemoteAndCreateAnswer() {
      const remoteSdp = JSON.parse(document.getElementById('remoteSdp').value);
      await createPeerConnection(false);
      await pc.setRemoteDescription(new RTCSessionDescription(remoteSdp));
      const answer = await pc.createAnswer();
      await pc.setLocalDescription(answer);
      document.getElementById('status').textContent = "Answer created";
      // startSpeechRecognition(); // Removed from here
    }

    async function setRemoteAnswer() {
      const remoteSdp = JSON.parse(document.getElementById('remoteSdp').value);
      await pc.setRemoteDescription(new RTCSessionDescription(remoteSdp));
      document.getElementById('status').textContent = "Remote answer set. Audio should work now.";
    }

    // Speech-to-Text (Web Speech API)
    let recognition;
    function startSpeechRecognition() {
      if (recognition && recognition.running) return; // Prevent multiple starts
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
        document.getElementById('status').textContent = "Speech Recognition not supported in this browser.";
        return;
      }
      recognition = new SpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'en-IN'; 
      recognition.onresult = function(event) {
        let transcript = '';
        for (let i = event.resultIndex; i < event.results.length; ++i) {
          transcript += event.results[i][0].transcript;
        }
        if (transcript.trim() !== '') {
          addTranscript('You', transcript);
          if (dataChannel && dataChannel.readyState === 'open') {
            dataChannel.send(transcript);
          }
        }
      };
      recognition.onerror = function(event) {
        document.getElementById('status').textContent = 'Speech recognition error: ' + event.error;
      };
      recognition.onend = function() {
        // Auto-restart for continuous recognition
        recognition.start();
      };
      recognition.start();
      recognition.running = true;
    }

    function addTranscript(who, text) {
      transcriptHistory.push(`${who}: ${text}`);
      document.getElementById('transcript').value = transcriptHistory.join('\n');
    }
  </script>\
  <script async type='module' src='https://interfaces.zapier.com/assets/web-components/zapier-interfaces/zapier-interfaces.esm.js'></script>
<zapier-interfaces-chatbot-embed is-popup='true' chatbot-id='cmdzv5hic0012od5x36k5fro8'></zapier-interfaces-chatbot-embed>
</body>
</html>

